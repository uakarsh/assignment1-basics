{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb171ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fc65367",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12f778f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world!\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1fea093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/akarshupadhyay/Desktop/my-work-repos/assignment1-basics/.venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b7feb9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dab7fbb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1114111"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1114111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbae2d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0000 followed by 2\n"
     ]
    }
   ],
   "source": [
    "print(f\"{chr(0)} followed by {chr(50)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1637aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\x00'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "caa3f81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0000\n"
     ]
    }
   ],
   "source": [
    "print(chr(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fcd86b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(\"'\\\\x00'\", None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(0).__repr__(), print(chr(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "585cb0f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is a test\\x00string'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"this is a test\" + chr(0) + \"string\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b67f7df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is a test\u0000string\n"
     ]
    }
   ],
   "source": [
    "print(\"this is a test\" + chr(0) + \"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "814c5078",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_string = \"hello! こんにちは!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c77d11a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "utf8_encoded = test_string.encode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "523c8b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'hello! \\xe3\\x81\\x93\\xe3\\x82\\x93\\xe3\\x81\\xab\\xe3\\x81\\xa1\\xe3\\x81\\xaf!'\n"
     ]
    }
   ],
   "source": [
    "print(utf8_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98a369bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bytes'>\n"
     ]
    }
   ],
   "source": [
    "print(type(utf8_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aef0e9cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[104,\n",
       " 101,\n",
       " 108,\n",
       " 108,\n",
       " 111,\n",
       " 33,\n",
       " 32,\n",
       " 227,\n",
       " 129,\n",
       " 147,\n",
       " 227,\n",
       " 130,\n",
       " 147,\n",
       " 227,\n",
       " 129,\n",
       " 171,\n",
       " 227,\n",
       " 129,\n",
       " 161,\n",
       " 227,\n",
       " 129,\n",
       " 175,\n",
       " 33]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(utf8_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cbbb2ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "print(len(test_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0f749c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "print(len(utf8_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e980f344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello! こんにちは!\n"
     ]
    }
   ],
   "source": [
    "print(utf8_encoded.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a78e797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_string.encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d1117cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_string.encode(\"utf-16\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1aaf4cad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_string.encode(\"utf-32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48990a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b's'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"s\".encode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec510401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of UTF-8 Encoded string: 54\n",
      "Length of UTF-16 Encoded string: 42\n",
      "Length of UTF-32 Encoded string: 84\n"
     ]
    }
   ],
   "source": [
    "test_string_hindi = \"आपको प्रणाम करता हूँ\"\n",
    "\n",
    "print(f'Length of UTF-8 Encoded string: {len(test_string_hindi.encode(\"utf-8\"))}')\n",
    "print(f'Length of UTF-16 Encoded string: {len(test_string_hindi.encode(\"utf-16\"))}')\n",
    "print(f'Length of UTF-32 Encoded string: {len(test_string_hindi.encode(\"utf-32\"))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86c6440f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of UTF-8 Encoded string: 17\n",
      "Length of UTF-16 Encoded string: 36\n",
      "Length of UTF-32 Encoded string: 72\n"
     ]
    }
   ],
   "source": [
    "test_string_english = \"my name is akarsh\"\n",
    "\n",
    "print(f'Length of UTF-8 Encoded string: {len(test_string_english.encode(\"utf-8\"))}')\n",
    "print(f'Length of UTF-16 Encoded string: {len(test_string_english.encode(\"utf-16\"))}')\n",
    "print(f'Length of UTF-32 Encoded string: {len(test_string_english.encode(\"utf-32\"))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19378e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[109, 121, 32, 110, 97, 109, 101, 32, 105, 115, 32, 97, 107, 97, 114, 115, 104]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(test_string_english.encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "053a5375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_utf8_bytes_to_str_wrong(bytestring: bytes):\n",
    "\n",
    "    list_of_bytes = []\n",
    "    flag: bool = False\n",
    "    for b in bytestring:\n",
    "        try:\n",
    "            list_of_bytes.append(bytes([b]).decode(\"utf-8\"))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            flag = True\n",
    "            print(b)\n",
    "            break\n",
    "\n",
    "    if not flag:\n",
    "        return \"\".join(list_of_bytes)\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "36ff8580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'utf-8' codec can't decode byte 0xe0 in position 0: unexpected end of data\n",
      "224\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_utf8_bytes_to_str_wrong(\"आपको प्रणाम करता हूँ\".encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b2806098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\xe0'\n"
     ]
    }
   ],
   "source": [
    "print(bytes([224]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dea200ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[224,\n",
       " 164,\n",
       " 134,\n",
       " 224,\n",
       " 164,\n",
       " 170,\n",
       " 224,\n",
       " 164,\n",
       " 149,\n",
       " 224,\n",
       " 165,\n",
       " 139,\n",
       " 32,\n",
       " 224,\n",
       " 164,\n",
       " 170,\n",
       " 224,\n",
       " 165,\n",
       " 141,\n",
       " 224,\n",
       " 164,\n",
       " 176,\n",
       " 224,\n",
       " 164,\n",
       " 163,\n",
       " 224,\n",
       " 164,\n",
       " 190,\n",
       " 224,\n",
       " 164,\n",
       " 174,\n",
       " 32,\n",
       " 224,\n",
       " 164,\n",
       " 149,\n",
       " 224,\n",
       " 164,\n",
       " 176,\n",
       " 224,\n",
       " 164,\n",
       " 164,\n",
       " 224,\n",
       " 164,\n",
       " 190,\n",
       " 32,\n",
       " 224,\n",
       " 164,\n",
       " 185,\n",
       " 224,\n",
       " 165,\n",
       " 130,\n",
       " 224,\n",
       " 164,\n",
       " 129]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(\"आपको प्रणाम करता हूँ\".encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "191b4e21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'आ'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bytes([224, 164, 134]).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65e456b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8756b8fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[224,\n",
       " 164,\n",
       " 134,\n",
       " 224,\n",
       " 164,\n",
       " 170,\n",
       " 224,\n",
       " 164,\n",
       " 149,\n",
       " 224,\n",
       " 165,\n",
       " 139,\n",
       " 32,\n",
       " 224,\n",
       " 164,\n",
       " 170,\n",
       " 224,\n",
       " 165,\n",
       " 141,\n",
       " 224,\n",
       " 164,\n",
       " 176,\n",
       " 224,\n",
       " 164,\n",
       " 163,\n",
       " 224,\n",
       " 164,\n",
       " 190,\n",
       " 224,\n",
       " 164,\n",
       " 174,\n",
       " 32,\n",
       " 224,\n",
       " 164,\n",
       " 149,\n",
       " 224,\n",
       " 164,\n",
       " 176,\n",
       " 224,\n",
       " 164,\n",
       " 164,\n",
       " 224,\n",
       " 164,\n",
       " 190,\n",
       " 32,\n",
       " 224,\n",
       " 164,\n",
       " 185,\n",
       " 224,\n",
       " 165,\n",
       " 130,\n",
       " 224,\n",
       " 164,\n",
       " 129]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(\"आपको प्रणाम करता हूँ\".encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7a765c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"b'\\\\xe0\\\\xa4'\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bytes([224, 164]).__repr__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f42a1d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAT = r\"\"\"'(?:[sdmt]|ll|ve|re)| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0012d267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0417450f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['some', ' text', ' that', ' i', \"'ll\", ' pre', '-', 'tokenize', \"'s\"]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(PAT, \"some text that i'll pre-tokenize's\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ff6219e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_stories_data_train = \"../data/TinyStoriesV2-GPT4-train.txt\"\n",
    "\n",
    "with open(tiny_stories_data_train, 'r', encoding = \"utf-8\") as f:\n",
    "    tiny_stories_data = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7c2cab59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.600057"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tiny_stories_data) / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ce48af48",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = iter(tiny_stories_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "29d59a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1b9f5b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\\n'\n",
      " 'Once upon a time there was a little boy named Ben. Ben loved to explore the '\n",
      " 'world around him. He saw many amazing things, like beautiful vases that were '\n",
      " 'on display in a store. One day, Ben was walking through the store when he '\n",
      " 'came across a very special vase. When Ben saw it he was amazed!  \\n'\n",
      " 'He said, “Wow, that is a really amazing vase! Can I buy it?” \\n'\n",
      " 'The shopkeeper smiled and said, “Of course you can. You can take it home and '\n",
      " 'show all your friends how amazing it is!”\\n'\n",
      " 'So Ben took the vase home and he was so proud of it! He called his friends '\n",
      " 'over and showed them the amazing vase. All his friends thought the vase was '\n",
      " \"beautiful and couldn't believe how lucky Ben was. \\n\"\n",
      " \"And that's how Ben found an amazing vase in the store!\\n\"\n",
      " '<|endoftext|>\\n'\n",
      " 'Once upon a time, there was a reliable otter named Ollie. He lived in a '\n",
      " 'river with his family. They all loved to play and swim together.\\n'\n",
      " 'One day, Ollie\\'s mom said, \"Ollie, hurry and get some fish for dinner!\" '\n",
      " 'Ollie swam fast to catch fish. He saw his friend, the duck. \"Hi, Ollie!\" '\n",
      " 'said the duck. \"Hi, duck!\" said Ollie. \"I need to hurry and catch fish for '\n",
      " 'my family.\"\\n'\n",
      " 'While Ollie was catching fish, he found a big shiny stone. He thought, \"This '\n",
      " 'is not a fish, but it is so pretty!\" Ollie took the shiny stone home to show '\n",
      " 'his family. They all looked at the shiny stone and smiled. The shiny stone '\n",
      " 'made everyone happy, and they forgot about the fish for dinner.\\n'\n",
      " '<|endoftext|>\\n'\n",
      " 'One day, a little boy named Tim went to the park. He saw a big tiger. The '\n",
      " 'tiger was not mean, but very easy to play with. Tim and the tiger played all '\n",
      " 'day. They had lots of fun.\\n'\n",
      " 'Then, something unexpected happened. The tiger started to shake. Tim was '\n",
      " 'scared. He did not know what was going on. But then, the tiger turned into a '\n",
      " 'nice dog. Tim was very surprised.\\n'\n",
      " 'Tim and the dog played together now. They were very happy. The dog was easy '\n",
      " 'to play with too. At the end of the day, Tim went home with his new friend.\\n'\n",
      " '<|endoftext|>\\n'\n",
      " '\\n'\n",
      " 'Once upon a time there was a friendly little boy called Bob. Bob loved to '\n",
      " 'pick flowers and look for birds. One day he decided to go outside with his '\n",
      " 'friends to pick some more flowers. \\n'\n",
      " 'He suddenly noticed something weird on the ground. It was a big, green '\n",
      " 'thumb! It was so big, Bob had never seen one before. Bob curiously leaned in '\n",
      " 'to take a better look. He told his friends: \"look everyone, I picked up this '\n",
      " 'big thumb! What do we do with it?\"\\n'\n",
      " 'His friends were very excited. They told him to pick it up and take it home '\n",
      " 'to show his family. So Bob carefully picked up the friendly thumb and '\n",
      " 'carried it back home. When he arrived, Bob happily showed the thumb to his '\n",
      " 'family. His dad was amazed and hugged Bob to show his appreciation.\\n'\n",
      " 'From that day on Bob always kept the big, friendly thumb with him as a '\n",
      " 'reminder that special things can be found anywhere.\\n')\n"
     ]
    }
   ],
   "source": [
    "pprint(\"\".join(tiny_stories_data[:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ba2a37a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cs336_basics.pretokenization_example import find_chunk_boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fad97c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_stories_data_val = \"../data/TinyStoriesV2-GPT4-valid.txt\"\n",
    "chunks = 100\n",
    "special_token = bytes(\"<|endoftext|>\".encode(\"utf-8\"))\n",
    "\n",
    "with open(tiny_stories_data_val, 'rb') as f:\n",
    "    chunk_size = find_chunk_boundaries(f, chunks, special_token)\n",
    "    strings_in_each_chunk = []\n",
    "\n",
    "    for curr_chunk, next_chunk in zip(chunk_size[:-1], chunk_size[1:]):\n",
    "        diff = next_chunk - curr_chunk\n",
    "        f.seek(curr_chunk)\n",
    "        strings_in_each_chunk.append(f.read(diff))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b090420e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chunk_strings_from_file(file_path:str, total_chunks: int, special_tokens: list[str]) -> list[str]:\n",
    "\n",
    "    with open(file_path, 'rb') as f:\n",
    "        chunks = find_chunk_boundaries(f, total_chunks, bytes(special_tokens[0].encode(\"utf-8\")))\n",
    "        strings_in_each_chunk = []\n",
    "\n",
    "        for curr_chunk, next_chunk in zip(chunks[:-1], chunks[1:]):\n",
    "            diff = next_chunk - curr_chunk\n",
    "            f.seek(curr_chunk)\n",
    "            strings_in_each_chunk.append(f.read(diff))\n",
    "\n",
    "        strings_in_each_chunk = list(map(lambda x : x.decode(\"utf-8\"), strings_in_each_chunk))\n",
    "    \n",
    "    return strings_in_each_chunk, chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c0728fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Assert that the reconstruction of `strings_in_each_chunk` leads to the original text\n",
    "\n",
    "# reconstructed_data = \"\".join([x.decode(\"utf-8\") for x in strings_in_each_chunk])\n",
    "\n",
    "\n",
    "# with open(tiny_stories_data_val, 'r', encoding = 'utf-8') as f:\n",
    "#     original_tiny_stories_data_val = f.readlines()\n",
    "#     original_tiny_stories_data_val = \"\".join(original_tiny_stories_data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f2799a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_tiny_stories_data_val == reconstructed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "51911126",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens = [\"<|endoftext|>\", \"[PAD]\", \"[SEP]\", \"[EOS]\", \"[CLS]\"]\n",
    "file_path = \"../data/TinyStoriesV2-GPT4-valid.txt\"\n",
    "total_chunks = 1000\n",
    "\n",
    "chunked_strings, chunks = get_chunk_strings_from_file(file_path=file_path, total_chunks=total_chunks, special_tokens=special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fddd9bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re.escape() adds backslashes to all special characters automatically\n",
    "escaped_tokens = [re.escape(t) for t in special_tokens]\n",
    "\n",
    "# Join them with the OR operator\n",
    "special_tokens_str = \"|\".join(escaped_tokens)\n",
    "\n",
    "# The | inside the brackets needs to be escaped: \\|\n",
    "# The | between the tokens should NOT be escaped: |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eb483333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_special_tokens(string_chunk : str, special_tokens_str: str) -> str:\n",
    "\n",
    "    ## a string_chunk always start with one of the special tokens\n",
    "    matches = re.finditer(special_tokens_str, string_chunk)\n",
    "    boundaries = []\n",
    "\n",
    "    ## find the occurence of the special tokens and strip them out\n",
    "    for match in matches:\n",
    "        current_span = match.span()\n",
    "        boundaries.append(current_span[0])\n",
    "        boundaries.append(current_span[1])\n",
    "\n",
    "    boundaries = boundaries[1:] ## since we want the text in b/w the special tokens and not the location of the special token itself\n",
    "    final_string_chunk = []\n",
    "    for i in range(0, len(boundaries)-1, 2):\n",
    "        final_string_chunk.append(string_chunk[boundaries[i]: boundaries[i+1]])\n",
    "\n",
    "    return \"\".join(final_string_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5ba99a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matches = re.finditer(special_tokens_str, chunked_strings[1])\n",
    "# boundaries = []\n",
    "\n",
    "# for match in matches:\n",
    "#     current_span = match.span()\n",
    "#     boundaries.append(current_span[0])\n",
    "#     boundaries.append(current_span[1])\n",
    "\n",
    "# boundaries = boundaries[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c9c8befc",
   "metadata": {},
   "outputs": [],
   "source": [
    "og_chunk = chunked_strings[1]\n",
    "stripped_chunk = strip_special_tokens(copy.deepcopy(og_chunk), special_tokens_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "35bfa0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "## Pre-tokenize\n",
    "\n",
    "tokens = re.findall(PAT, stripped_chunk)\n",
    "tokens_with_count = defaultdict(int)\n",
    "\n",
    "for token in tokens:\n",
    "    tokens_with_count[token] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fe4a18c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_pairs_after_pretokenization(tokens_with_count) -> list[tuple[bytes, bytes], int]:\n",
    "    '''\n",
    "        - This step is done after we have pre-tokenized followed by converting the string to byte\n",
    "    '''\n",
    "\n",
    "    pair_count = defaultdict(int)\n",
    "    for each_token in tokens_with_count.keys():\n",
    "        byte_array = bytes(each_token.encode(\"utf-8\"))\n",
    "        for i, j in zip(byte_array, byte_array[1:]):\n",
    "            pair_count[(i, j)] += tokens_with_count[each_token]\n",
    "\n",
    "    return pair_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "725f88f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_merge = count_pairs_after_pretokenization(tokens_with_count=tokens_with_count)\n",
    "first_merge_pair = max(first_merge, key=first_merge.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1fe18dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most frequent pair is: 'h' and 'e'\n",
      "Combined, they form: 'he'\n"
     ]
    }
   ],
   "source": [
    "# first_merge_pair is something like (104, 101) for 'he'\n",
    "# Convert the integers to a bytes object, then decode to string\n",
    "char_a = bytes([first_merge_pair[0]]).decode(\"utf-8\", errors=\"replace\")\n",
    "char_b = bytes([first_merge_pair[1]]).decode(\"utf-8\", errors=\"replace\")\n",
    "\n",
    "print(f\"The most frequent pair is: '{char_a}' and '{char_b}'\")\n",
    "print(f\"Combined, they form: '{char_a + char_b}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "17bab54f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104, 101)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_merge_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "faa747be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pre_tokenization_and_count_on_chunk_of_string(chunk_of_string, special_tokens_str:str = '<\\\\|endoftext\\\\|>|\\\\[PAD\\\\]|\\\\[SEP\\\\]|\\\\[EOS\\\\]|\\\\[CLS\\\\]', pre_tokenization_regex:str = r\"\"\"'(?:[sdmt]|ll|ve|re)| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\"):\n",
    "    '''\n",
    "        - strip the special tokens\n",
    "        - pre-tokenize and get count of each token\n",
    "        - return the  (pair of token, count)\n",
    "    '''\n",
    "\n",
    "    start = time.time()\n",
    "    print(\"[Step:1] Stripping the special token\")\n",
    "    stripped_chunk = strip_special_tokens(chunk_of_string, special_tokens_str)\n",
    "\n",
    "    tokens = re.findall(pre_tokenization_regex, stripped_chunk)\n",
    "    tokens_with_count = defaultdict(int)\n",
    "\n",
    "    print(\"[Step:2] Counting the tokens\")\n",
    "    for token in tokens:\n",
    "        tokens_with_count[token] += 1\n",
    "\n",
    "    print(\"[Step:3] Finding the occurence of all pairs across the different tokens\")\n",
    "    byte_pair_with_count = count_pairs_after_pretokenization(tokens_with_count=tokens_with_count)\n",
    "    print(f\"Worker finished in {time.time() - start:.6f}s\")\n",
    "    return byte_pair_with_count\n",
    "\n",
    "\n",
    "def run_pre_tokenization_and_count_on_chunk_of_string_with_offset(offset, special_tokens_str:str = '<\\\\|endoftext\\\\|>|\\\\[PAD\\\\]|\\\\[SEP\\\\]|\\\\[EOS\\\\]|\\\\[CLS\\\\]', pre_tokenization_regex:str = r\"\"\"'(?:[sdmt]|ll|ve|re)| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\"):\n",
    "    '''\n",
    "        - strip the special tokens\n",
    "        - pre-tokenize and get count of each token\n",
    "        - return the  (pair of token, count)\n",
    "    '''\n",
    "\n",
    "    #start = time.time()\n",
    "    # print(\"[Step:1] Stripping the special token\")\n",
    "\n",
    "    curr_chunk = offset[0]\n",
    "    next_chunk = offset[1]\n",
    "    diff = next_chunk - curr_chunk\n",
    "\n",
    "    global file_path\n",
    "    with open(file_path, 'rb') as f: ## Hardcoded in global variable\n",
    "        f.seek(curr_chunk)\n",
    "        chunk_of_string = f.read(diff).decode(\"utf-8\")\n",
    "        \n",
    "    stripped_chunk = strip_special_tokens(chunk_of_string, special_tokens_str)\n",
    "\n",
    "    tokens = re.findall(pre_tokenization_regex, stripped_chunk)\n",
    "    tokens_with_count = defaultdict(int)\n",
    "\n",
    "    # print(\"[Step:2] Counting the tokens\")\n",
    "    for token in tokens:\n",
    "        tokens_with_count[token] += 1\n",
    "\n",
    "    # print(\"[Step:3] Finding the occurence of all pairs across the different tokens\")\n",
    "    byte_pair_with_count = count_pairs_after_pretokenization(tokens_with_count=tokens_with_count)\n",
    "    # print(f\"Worker finished in {time.time() - start:.6f}s\")\n",
    "    return byte_pair_with_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "17db946a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step:1] Stripping the special token\n",
      "[Step:2] Counting the tokens\n",
      "[Step:3] Finding the occurence of all pairs across the different tokens\n",
      "Worker finished in 0.001802s\n"
     ]
    }
   ],
   "source": [
    "chunk_of_string = chunked_strings[1]\n",
    "special_tokens = [\"<|endoftext|>\", \"[PAD]\", \"[SEP]\", \"[EOS]\", \"[CLS]\"]\n",
    "escaped_tokens = [re.escape(t) for t in special_tokens]\n",
    "special_tokens_str = \"|\".join(escaped_tokens)\n",
    "pre_tokenization_regex = r\"\"\"'(?:[sdmt]|ll|ve|re)| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\"\n",
    "\n",
    "byte_pair_with_count = run_pre_tokenization_and_count_on_chunk_of_string(chunk_of_string, special_tokens_str=special_tokens_str, pre_tokenization_regex = pre_tokenization_regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "57b9ccff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<\\\\|endoftext\\\\|>|\\\\[PAD\\\\]|\\\\[SEP\\\\]|\\\\[EOS\\\\]|\\\\[CLS\\\\]'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "special_tokens_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "83b222db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {(79, 110): 27,\n",
       "             (110, 99): 20,\n",
       "             (99, 101): 63,\n",
       "             (32, 117): 34,\n",
       "             (117, 112): 27,\n",
       "             (112, 111): 32,\n",
       "             (111, 110): 84,\n",
       "             (32, 97): 480,\n",
       "             (32, 116): 620,\n",
       "             (116, 105): 52,\n",
       "             (105, 109): 55,\n",
       "             (109, 101): 84,\n",
       "             (32, 105): 125,\n",
       "             (105, 110): 199,\n",
       "             (32, 119): 298,\n",
       "             (119, 97): 154,\n",
       "             (97, 114): 123,\n",
       "             (114, 109): 3,\n",
       "             (97, 110): 346,\n",
       "             (110, 100): 285,\n",
       "             (32, 115): 318,\n",
       "             (115, 117): 11,\n",
       "             (117, 110): 40,\n",
       "             (110, 110): 8,\n",
       "             (110, 121): 10,\n",
       "             (32, 112): 120,\n",
       "             (112, 108): 32,\n",
       "             (108, 97): 61,\n",
       "             (97, 99): 39,\n",
       "             (116, 104): 420,\n",
       "             (104, 101): 618,\n",
       "             (101, 114): 231,\n",
       "             (114, 101): 172,\n",
       "             (97, 115): 148,\n",
       "             (32, 98): 203,\n",
       "             (98, 105): 43,\n",
       "             (105, 103): 41,\n",
       "             (112, 105): 24,\n",
       "             (105, 116): 128,\n",
       "             (32, 65): 19,\n",
       "             (32, 108): 139,\n",
       "             (108, 105): 85,\n",
       "             (116, 116): 46,\n",
       "             (116, 108): 37,\n",
       "             (108, 101): 123,\n",
       "             (98, 111): 41,\n",
       "             (111, 121): 20,\n",
       "             (32, 110): 101,\n",
       "             (110, 97): 21,\n",
       "             (97, 109): 32,\n",
       "             (101, 100): 258,\n",
       "             (32, 84): 160,\n",
       "             (84, 111): 51,\n",
       "             (111, 109): 149,\n",
       "             (105, 107): 21,\n",
       "             (107, 101): 102,\n",
       "             (116, 111): 229,\n",
       "             (97, 121): 80,\n",
       "             (110, 101): 80,\n",
       "             (101, 97): 100,\n",
       "             (32, 79): 9,\n",
       "             (32, 100): 110,\n",
       "             (100, 97): 42,\n",
       "             (108, 111): 79,\n",
       "             (111, 115): 11,\n",
       "             (115, 116): 104,\n",
       "             (32, 104): 257,\n",
       "             (104, 105): 76,\n",
       "             (105, 115): 77,\n",
       "             (32, 114): 60,\n",
       "             (98, 97): 31,\n",
       "             (97, 108): 64,\n",
       "             (108, 108): 89,\n",
       "             (32, 72): 51,\n",
       "             (72, 101): 51,\n",
       "             (32, 118): 28,\n",
       "             (118, 101): 103,\n",
       "             (114, 121): 62,\n",
       "             (115, 97): 98,\n",
       "             (97, 100): 77,\n",
       "             (115, 107): 24,\n",
       "             (32, 102): 139,\n",
       "             (102, 114): 18,\n",
       "             (114, 105): 43,\n",
       "             (105, 101): 33,\n",
       "             (101, 110): 95,\n",
       "             (32, 83): 77,\n",
       "             (83, 97): 15,\n",
       "             (101, 108): 62,\n",
       "             (108, 112): 15,\n",
       "             (115, 101): 51,\n",
       "             (114, 99): 3,\n",
       "             (99, 104): 31,\n",
       "             (102, 111): 51,\n",
       "             (111, 114): 100,\n",
       "             (84, 104): 127,\n",
       "             (101, 121): 111,\n",
       "             (111, 111): 81,\n",
       "             (111, 107): 42,\n",
       "             (103, 104): 18,\n",
       "             (111, 119): 62,\n",
       "             (98, 117): 31,\n",
       "             (117, 116): 62,\n",
       "             (32, 99): 116,\n",
       "             (99, 111): 26,\n",
       "             (111, 117): 146,\n",
       "             (117, 108): 45,\n",
       "             (108, 100): 30,\n",
       "             (110, 111): 54,\n",
       "             (111, 116): 75,\n",
       "             (102, 105): 19,\n",
       "             (97, 105): 82,\n",
       "             (105, 100): 98,\n",
       "             (32, 34): 38,\n",
       "             (110, 107): 15,\n",
       "             (32, 109): 133,\n",
       "             (109, 121): 25,\n",
       "             (102, 101): 33,\n",
       "             (110, 116): 82,\n",
       "             (46, 34): 22,\n",
       "             (119, 101): 72,\n",
       "             (99, 108): 18,\n",
       "             (115, 99): 12,\n",
       "             (99, 97): 65,\n",
       "             (116, 101): 88,\n",
       "             (114, 107): 16,\n",
       "             (101, 101): 36,\n",
       "             (87, 101): 9,\n",
       "             (109, 117): 11,\n",
       "             (117, 115): 24,\n",
       "             (32, 103): 77,\n",
       "             (103, 111): 31,\n",
       "             (32, 73): 36,\n",
       "             (73, 116): 16,\n",
       "             (116, 114): 34,\n",
       "             (103, 101): 29,\n",
       "             (101, 116): 60,\n",
       "             (32, 111): 108,\n",
       "             (100, 101): 61,\n",
       "             (101, 112): 16,\n",
       "             (116, 117): 19,\n",
       "             (117, 99): 20,\n",
       "             (99, 107): 46,\n",
       "             (101, 109): 24,\n",
       "             (101, 118): 15,\n",
       "             (111, 102): 35,\n",
       "             (10, 10): 15,\n",
       "             (32, 76): 38,\n",
       "             (76, 105): 44,\n",
       "             (105, 108): 88,\n",
       "             (108, 121): 65,\n",
       "             (121, 105): 9,\n",
       "             (110, 103): 110,\n",
       "             (119, 105): 55,\n",
       "             (101, 105): 34,\n",
       "             (105, 114): 63,\n",
       "             (121, 115): 11,\n",
       "             (105, 118): 11,\n",
       "             (118, 105): 3,\n",
       "             (114, 111): 37,\n",
       "             (117, 105): 6,\n",
       "             (114, 115): 19,\n",
       "             (98, 114): 15,\n",
       "             (100, 103): 2,\n",
       "             (101, 115): 76,\n",
       "             (98, 108): 20,\n",
       "             (111, 99): 10,\n",
       "             (107, 115): 9,\n",
       "             (112, 114): 15,\n",
       "             (117, 100): 8,\n",
       "             (116, 97): 38,\n",
       "             (109, 97): 52,\n",
       "             (97, 107): 27,\n",
       "             (32, 101): 46,\n",
       "             (115, 111): 58,\n",
       "             (109, 111): 54,\n",
       "             (104, 97): 156,\n",
       "             (97, 118): 32,\n",
       "             (63, 34): 21,\n",
       "             (83, 104): 51,\n",
       "             (78, 111): 4,\n",
       "             (109, 105): 22,\n",
       "             (32, 71): 7,\n",
       "             (71, 111): 1,\n",
       "             (32, 121): 59,\n",
       "             (121, 111): 60,\n",
       "             (117, 114): 35,\n",
       "             (119, 110): 8,\n",
       "             (44, 34): 10,\n",
       "             (100, 105): 25,\n",
       "             (115, 104): 45,\n",
       "             (115, 105): 15,\n",
       "             (112, 117): 12,\n",
       "             (108, 116): 14,\n",
       "             (103, 114): 13,\n",
       "             (98, 101): 48,\n",
       "             (110, 105): 29,\n",
       "             (105, 99): 39,\n",
       "             (97, 116): 128,\n",
       "             (101, 99): 31,\n",
       "             (99, 105): 14,\n",
       "             (83, 117): 15,\n",
       "             (100, 100): 10,\n",
       "             (110, 108): 3,\n",
       "             (100, 111): 29,\n",
       "             (99, 114): 20,\n",
       "             (114, 97): 55,\n",
       "             (65, 108): 3,\n",
       "             (102, 108): 19,\n",
       "             (104, 111): 43,\n",
       "             (114, 100): 23,\n",
       "             (114, 117): 8,\n",
       "             (117, 109): 20,\n",
       "             (109, 98): 3,\n",
       "             (114, 116): 35,\n",
       "             (104, 113): 2,\n",
       "             (113, 117): 4,\n",
       "             (117, 97): 2,\n",
       "             (77, 111): 21,\n",
       "             (109, 109): 13,\n",
       "             (32, 68): 5,\n",
       "             (68, 97): 4,\n",
       "             (100, 121): 14,\n",
       "             (33, 34): 11,\n",
       "             (112, 97): 27,\n",
       "             (116, 115): 15,\n",
       "             (119, 104): 31,\n",
       "             (32, 107): 30,\n",
       "             (107, 105): 30,\n",
       "             (116, 99): 9,\n",
       "             (65, 114): 2,\n",
       "             (107, 97): 5,\n",
       "             (100, 115): 12,\n",
       "             (32, 77): 39,\n",
       "             (104, 117): 13,\n",
       "             (117, 103): 18,\n",
       "             (103, 103): 7,\n",
       "             (105, 102): 17,\n",
       "             (39, 114): 1,\n",
       "             (32, 66): 22,\n",
       "             (66, 117): 14,\n",
       "             (39, 109): 8,\n",
       "             (114, 114): 17,\n",
       "             (109, 112): 8,\n",
       "             (32, 89): 15,\n",
       "             (89, 111): 15,\n",
       "             (32, 87): 11,\n",
       "             (97, 102): 10,\n",
       "             (111, 103): 18,\n",
       "             (39, 115): 30,\n",
       "             (105, 122): 3,\n",
       "             (122, 101): 3,\n",
       "             (108, 102): 2,\n",
       "             (97, 119): 24,\n",
       "             (100, 117): 2,\n",
       "             (97, 112): 31,\n",
       "             (112, 112): 37,\n",
       "             (112, 121): 22,\n",
       "             (111, 118): 18,\n",
       "             (115, 109): 16,\n",
       "             (114, 103): 3,\n",
       "             (103, 97): 25,\n",
       "             (111, 108): 19,\n",
       "             (108, 115): 15,\n",
       "             (110, 115): 9,\n",
       "             (119, 111): 19,\n",
       "             (114, 110): 24,\n",
       "             (102, 97): 9,\n",
       "             (115, 119): 6,\n",
       "             (103, 105): 24,\n",
       "             (114, 108): 13,\n",
       "             (76, 117): 10,\n",
       "             (99, 121): 11,\n",
       "             (117, 121): 3,\n",
       "             (115, 112): 14,\n",
       "             (112, 101): 37,\n",
       "             (105, 97): 4,\n",
       "             (101, 120): 8,\n",
       "             (120, 99): 4,\n",
       "             (65, 115): 4,\n",
       "             (111, 100): 24,\n",
       "             (111, 105): 11,\n",
       "             (76, 101): 4,\n",
       "             (101, 102): 6,\n",
       "             (102, 117): 20,\n",
       "             (72, 97): 1,\n",
       "             (83, 111): 8,\n",
       "             (67, 97): 7,\n",
       "             (102, 116): 7,\n",
       "             (97, 103): 10,\n",
       "             (121, 101): 19,\n",
       "             (73, 110): 1,\n",
       "             (115, 115): 23,\n",
       "             (110, 102): 1,\n",
       "             (99, 116): 4,\n",
       "             (65, 110): 9,\n",
       "             (104, 121): 3,\n",
       "             (97, 117): 21,\n",
       "             (101, 103): 4,\n",
       "             (103, 115): 7,\n",
       "             (115, 121): 4,\n",
       "             (77, 97): 20,\n",
       "             (97, 120): 19,\n",
       "             (65, 116): 4,\n",
       "             (100, 98): 3,\n",
       "             (98, 121): 8,\n",
       "             (66, 101): 11,\n",
       "             (115, 108): 8,\n",
       "             (107, 110): 8,\n",
       "             (101, 119): 15,\n",
       "             (116, 119): 3,\n",
       "             (111, 120): 5,\n",
       "             (103, 108): 6,\n",
       "             (111, 112): 10,\n",
       "             (116, 121): 8,\n",
       "             (100, 114): 10,\n",
       "             (107, 108): 5,\n",
       "             (114, 102): 2,\n",
       "             (104, 116): 11,\n",
       "             (108, 117): 7,\n",
       "             (109, 115): 2,\n",
       "             (121, 116): 1,\n",
       "             (32, 80): 2,\n",
       "             (80, 108): 1,\n",
       "             (39, 116): 11,\n",
       "             (116, 102): 2,\n",
       "             (116, 112): 1,\n",
       "             (103, 100): 2,\n",
       "             (117, 98): 7,\n",
       "             (120, 101): 6,\n",
       "             (111, 97): 6,\n",
       "             (87, 104): 10,\n",
       "             (103, 117): 2,\n",
       "             (32, 113): 1,\n",
       "             (97, 98): 17,\n",
       "             (98, 98): 9,\n",
       "             (110, 106): 3,\n",
       "             (106, 111): 10,\n",
       "             (102, 102): 9,\n",
       "             (119, 114): 1,\n",
       "             (104, 115): 1,\n",
       "             (76, 111): 1,\n",
       "             (68, 111): 5,\n",
       "             (100, 108): 7,\n",
       "             (86, 101): 1,\n",
       "             (87, 111): 1,\n",
       "             (89, 101): 3,\n",
       "             (79, 75): 3,\n",
       "             (117, 101): 17,\n",
       "             (32, 106): 12,\n",
       "             (106, 97): 1,\n",
       "             (32, 67): 5,\n",
       "             (72, 111): 2,\n",
       "             (121, 98): 6,\n",
       "             (32, 39): 1,\n",
       "             (84, 119): 2,\n",
       "             (83, 116): 1,\n",
       "             (39, 63): 1,\n",
       "             (107, 121): 5,\n",
       "             (117, 102): 1,\n",
       "             (102, 121): 1,\n",
       "             (77, 101): 1,\n",
       "             (79, 102): 1,\n",
       "             (108, 107): 6,\n",
       "             (83, 108): 1,\n",
       "             (39, 108): 2,\n",
       "             (32, 69): 5,\n",
       "             (69, 118): 2,\n",
       "             (121, 97): 3,\n",
       "             (106, 117): 4,\n",
       "             (121, 117): 3,\n",
       "             (84, 105): 12,\n",
       "             (71, 105): 7,\n",
       "             (118, 111): 1,\n",
       "             (99, 99): 1,\n",
       "             (119, 108): 7,\n",
       "             (105, 120): 5,\n",
       "             (120, 105): 2,\n",
       "             (108, 119): 2,\n",
       "             (100, 110): 3,\n",
       "             (69, 109): 5,\n",
       "             (32, 45): 1,\n",
       "             (120, 104): 1,\n",
       "             (114, 112): 1,\n",
       "             (77, 117): 2,\n",
       "             (34, 46): 5,\n",
       "             (99, 117): 5,\n",
       "             (79, 104): 3,\n",
       "             (120, 116): 3,\n",
       "             (82, 101): 1,\n",
       "             (110, 117): 1,\n",
       "             (115, 113): 1,\n",
       "             (65, 102): 2,\n",
       "             (66, 121): 3,\n",
       "             (84, 117): 1,\n",
       "             (32, 78): 1,\n",
       "             (100, 118): 1,\n",
       "             (77, 121): 1,\n",
       "             (104, 114): 1,\n",
       "             (77, 109): 1,\n",
       "             (105, 111): 2,\n",
       "             (80, 101): 1,\n",
       "             (108, 109): 1,\n",
       "             (121, 109): 1})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_pre_tokenization_and_count_on_chunk_of_string_with_offset((chunks[0], chunks[1]), special_tokens_str=special_tokens_str, pre_tokenization_regex = pre_tokenization_regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1f5265ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_of_string_for_multiprocessing = []\n",
    "\n",
    "for i in range(len(chunks)-1):\n",
    "    chunk_of_string_for_multiprocessing.append(( (chunks[i], chunks[i+1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8d444002",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Applying multi-processing\n",
    "\n",
    "#from multiprocessing import Pool\n",
    "from pathos.multiprocessing import ProcessPool as Pool\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with Pool(5) as pool:\n",
    "        results = pool.map(run_pre_tokenization_and_count_on_chunk_of_string_with_offset, chunk_of_string_for_multiprocessing)\n",
    "    final_result = defaultdict(int)\n",
    "    for i in results:\n",
    "        for j in i:\n",
    "            final_result[j] += i[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "61c7ebae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most frequent pair is: ' ' and 't'\n",
      "Combined, they form: ' t'\n"
     ]
    }
   ],
   "source": [
    "merge_pair = max(final_result, key= final_result.get)\n",
    "# first_merge_pair is something like (104, 101) for 'he'\n",
    "# Convert the integers to a bytes object, then decode to string\n",
    "char_a = bytes([merge_pair[0]]).decode(\"utf-8\", errors=\"replace\")\n",
    "char_b = bytes([merge_pair[1]]).decode(\"utf-8\", errors=\"replace\")\n",
    "\n",
    "print(f\"The most frequent pair is: '{char_a}' and '{char_b}'\")\n",
    "print(f\"Combined, they form: '{char_a + char_b}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605860af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs336-basics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
